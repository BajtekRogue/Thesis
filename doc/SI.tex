\section{Dwa wierzchołki, jedna krawędź}

Na samym początku rozważmy najprostrzy graf, czyli o dwoch wierzchołkach $u,v$ połączonych krawędzią. Za wierzchołek startowy wybierzmy $u$. W tym przypadku istnieją tylko dwa możliwe stany systemu: $(I,S)$ oraz $(I,I)$. Przejście ze stanu $(I, S)$ do $(I, I)$ następuje z prawdopodobieństwem $p$ w każdej jednostce czasu. Zatem czas zarażenia drugiego wierzchołka $X_v$ ma rozkład geometryczny, $X_v \sim \mathrm{Geo}(p)$. Jeśli chodzi o rozkład $Y_t$ to mamy:
\begin{itemize}
    \item $\mathbb{P}[Y_t=1]=q^t$, bo próba zarażenia musiałaby nie udać się $t$ razy
    \item $\mathbb{P}[Y_t=2]=1-q^t$
\end{itemize}
Stąd $\mathbb{E}[Y_t]=1\cdot q^t + 2 \cdot (1-q^t) = 2-q^t$. Jeśli chodzi o zmienną $Z$ to zachodzi $Z=\max\{X_u,X_v\}=X_v$ a więc również $Z\sim \mathrm{Geo}(p)$.

\section{Analiza dla grafów $\mathrm{P}_n$}

Jako pierwszą rodzinę grafów rozważmy grafy ścieżkowe $\mathrm{P}_n$. Bez straty ogólności niech $V=\{1,2,\dots,n\}$. Załóżmy, że proces zaczyna się w wierzchołku $s=1$. Zatem infekcja rozchodzi się po grafie "od lewej do prawej". Dla tej rodziny grafów uda nam się wyznaczyć dokładny rozkład prawdopodobieństwa. \\
Dla ścieżki $\mathrm{P}_n$ z wierzchołkiem początkowym $s=1$,  
czasy zarażenia kolejnych wierzchołków tworzą ciąg zmiennych losowych
\[
X_1 = 0, \quad X_{k} = X_{k-1} + U_k, \quad k\in\{2,3,\dots,n\},
\]
gdzie $U_1,U_2,\dots,U_n \sim \mathrm{Geo}(p)$ oraz $U_1,U_2,\dots,U_n$ są niezależne. 

Widzimy zatem, że
\[
X_k \sim U_1 + U_2 + \dots + U_{k-1},
\]
a więc z faktu ~\ref{F:sum_of_geo_RV} $X_k$ ma rozkład ujemny dwumianowy o parametrach $(k-1, p)$, 
\[
X_k\sim \mathrm{NegBin}(k-1, p).
\]

Ponadto mamy:
\begin{itemize}
    \item $\mathbb{E}[X_k] = \frac{k-1}{p}$,
    \item $\mathrm{Var}[X_k] = \frac{(k-1)(1-p)}{p^2}$.
\end{itemize}

Aby obliczyć rozkład $Y_t$ zauważmy, że liczba dodatkowych zakażeń poza startowym wierzchołkiem do czasu $t$ to po prostu liczba sukcesów w $t$ niezależnych prób Bernoulliego. Musimy jednak pamiętać, że $Y_t$ nie może przekroczyć $n$. Zatem mamy dokładnie
\[
Y_t = \min\{n, 1 + B_t\}, \quad \text{gdzie} \quad B_t \sim \mathrm{Bin}(t,p).
\]
Pozwala to na wyznaczenie PMF dla $Y_t$:

Dla $1 \le k \le n-1$ mamy:
\[
\mathbb{P}[Y_t=k] = \mathbb{P}[B_t=k-1] = \binom{t}{k-1} p^{k-1} q^{t-k+1},
\]  

oraz dla $k = n$ mamy:
\[
\mathbb{P}[Y_t=n] = \mathbb{P}[B_t \ge n-1] = \sum_{j=n-1}^{t} \binom{t}{j} p^j q^{t-j}.
\]

Przejdźmy teraz do obliczania wartości oczekiwanej $Y_t$:
\begin{align*}
\mathbb{E}[Y_t] 
&= \sum_{k=1}^{n-1} k \cdot \mathbb{P}[Y_t=k] + n \cdot \mathbb{P}[Y_t=n] \\
&= \sum_{k=1}^{n-1} k \cdot \binom{t}{k-1} p^{k-1} q^{t-k+1} 
   + n \cdot \sum_{j=n-1}^{t} \binom{t}{j} p^j q^{t-j}.
\end{align*}

W pierwszej sumie podstawiamy $j = k-1$, co pozwala nam złączyć obie sumy i otrzymać:
\[
    \mathbb{E}[Y_t] = \sum_{j=0}^{t} \min\{n, 1+j\} \binom{t}{j} p^j q^{t-j}.
\]

Policzmy teraz asymptotykę dla $n \to \infty$. Wtedy $n > 1 + j$ dla wszystkich $0 \le j \le t$, a więc:
\[
    \lim_{n \to \infty}\mathbb{E}[Y_t] = \sum_{j=0}^{t} (1+j) \binom{t}{j} p^j q^{t-j}.
\]
Rozdzielając sumę na dwa składniki, otrzymujemy:
\[
    \lim_{n \to \infty}\mathbb{E}[Y_t] = \sum_{j=0}^{t} \binom{t}{j} p^j q^{t-j} 
+ \sum_{j=0}^{t} j \binom{t}{j} p^j q^{t-j}.
\]
Korzystając z ~\ref{F:binomial} oraz ~\ref{F:binomial1} otrzymujemy
\[
    (p+q)^t+tp(p+q)^{t-1}=1+tp
\]
Zatem
\[
    \lim_{n \to \infty}\mathbb{E}[Y_t] = 1+tp.
\]

Czas całkowitego zainfekowania grafu $\mathrm{P}_n$ to $Z = \max\{X_1,X_2,\dots,X_n\} = X_n$. Zatem rozkład zmiennej $Z$ jest już nam znany a wartość oczekiwana wynosi 
\[
    \mathbb{E}[Z]=\frac{n-1}{p}.
\]
\noindent
Jeśli wierzchołek początkowy $s \ne 1, n$, to proces rozprzestrzeniania się infekcji możemy rozdzielić na dwa niezależne procesy stochastyczne, 
zachodzące na podgrafach indukowanych przez zbiory:
\[
V_1 = \{1, 2, \dots, s\}, \qquad 
V_2 = \{s, s+1, \dots, n\}.
\]
Każdy z tych procesów ma charakter modelu SI na ścieżce, 
z tym że infekcja w wierzchołku $s$ pełni rolę źródła w obu częściach.


\section{Analiza dla grafów $\mathrm{S}_n$}

Następnie rozpatrzmy rodzinę grafów gwiazd $\mathrm{S}_n$. Przyjmujemy $V=\{0,1,2,\dots,n\}$ oraz, że wierzchołek $0$ jest środkiem gwiazdy. W modelu dla tej rodziny zakładamy również $s=0$. Propagacja rozchodzi się tutaj po każdym ramieniu gwiazdy niezależnie. 
Stąd mamy $X_v \sim \mathrm{Geo}(p)$ dla każdego $v\in\{1,2,\dots,n\}$. Zauważmy ponadto, że zmienne $X_1,X_2,\dots,X_n$ są od siebie niezależne.\\

Kwestia $Y_t$ jest również dość prosta. Skoro każdy propagacja działa na każdym wierzchołku niezależnie to zmienna $Y_t$ jest wynikiem $n$ prób Bernoulliego. Sukces pojedynczej próby to prawdopodobieństwo, że zmienna $X_v$ o rozkładzie geometrycznym po conajwyżej $t$ jednostkach czasu osiągnie swój sukces. A więc jest to $\mathbb{P}[X_v\le t]=1-q^t$. Podsumowując mamy
\[
    Y_t \sim \mathrm{Bin}(n, 1-q^t)
\]
Stąd oczywiście otrzymujemy 
\[
    \mathbb{E}[Y_t] = n\cdot (1-q^t). 
\]

Przejdźmy teraz to zmiennej $Z$. Przypomnijmy, że $Z=\max\{X_1,X_2,\dots,X_n\}$. Skoro zmienne te są IID, to z ~\ref{F:max_CDF} mamy 
\[
    \mathbb{P}[Z\le t] = (1-q^t)^n
\]
Policzmy teraz wartość oczekiwaną $Z$ na mocy ~\ref{F:expected_value_tail_sum}:
\begin{align*}
\mathbb{E}[Z] 
&= \sum_{k=1}^{\infty} \mathbb{P}[Z\ge k] 
 = \sum_{k=1}^{\infty} 1 - \mathbb{P}[Z\le k-1]
 = \sum_{k=1}^{\infty}  1 - (1-q^{k-1})^n  \\
&= \sum_{k=0}^{\infty}  1 - (1-q^k)^n 
 = \sum_{k=0}^{\infty} \left( 1 - \sum_{j=0}^{n} \binom{n}{j} (-1)^j q^{kj} \right) 
 = \sum_{k=0}^{\infty} \sum_{j=1}^{n} \binom{n}{j} (-1)^{j+1} q^{kj} \\
&= \sum_{j=1}^{n} \sum_{k=0}^{\infty} \binom{n}{j} (-1)^{j+1} (q^j)^k 
 = \sum_{j=1}^{n} \binom{n}{j} \frac{(-1)^{j+1}}{1-q^j}.
\end{align*}
Nie jest to jednak przyzwoity wynik i nie ma postaci zwartej. Spróbujmy zatem wyznaczyć asymptotykę $\mathbb{E}[Z]$. Skoro $\mathbb{E}[Z] = \sum_{k=0}^{\infty}  1 - (1-q^k)^n$ to z \ref{T:approximation_of_sum_by_an_integral} możemy oszacować tą sumę. Połóżmy $f(x) = 1 - (1 - e^{-\alpha x})^n$ gdzie $\alpha = -\log(q)$. Oczywiście $f(0)=1$ , $f(\infty)=0$ oraz $f$ jest malejąca a więc
\[
    \int_{0}^{\infty} f(x) \; \mathrm{d}x \le \mathbb{E}[Z] \le  1 + \int_{0}^{\infty} f(x) \; \mathrm{d}x
\]
Całka ta jest równa $\frac{-1}{\log(q)} H_n$ (patrz ~\ref{F:integral_1}). Finalnie, podstawiając $H_n \sim \log(n)$ jak i $-\log(q)=\log(\frac{1}{1-p})$ otrzymujemy
\[
    \mathbb{E}[Z] \sim \frac{\log(n)}{\log(\frac{1}{1-p})}
\]


\section{Analiza dla drzew}

Rozważmy drzewo $G = (V, E)$ oraz ustalony wierzchołek początkowy $s \in V$, 
który traktujemy jako \textbf{korzeń drzewa}. Niech $v\in V\setminus\{s\}$ oraz $d=\mathrm{d}(s,v)$. Istnieje dokładnie jedna ścieżka od $s$ do $v$, powiedzmy $s,v_1,...,v_{d-1}, v$. Ponieważ infekcja rozprzestrzenia się od korzenia $s$ wzdłuż krawędzi drzewa, 
każde zakażenie wymaga sukcesu w niezależnym doświadczeniu Bernoulliego o prawdopodobieństwie $p$.
W konsekwencji, aby infekcja dotarła z $s$ do $v$, 
musi wystąpić $\mathrm{d}(s,v)$ kolejnych sukcesów. Zatem rozkład $X_v$ pokrywa się z rozkładem tej zmiennej dla grafu $\mathrm{P}_{d+1}$ na wierzchołkach $\{s,v_1,...,v_{d-1}, v\}$. 
Zatem 
\[
    X_v\sim \mathrm{NegBin}(\mathrm{d}(s,v),p)
\]
oraz
\begin{itemize}
    \item $\mathbb{E}[X_v] = \frac{\mathrm{d}(s,v)}{p}$
    \item $\mathrm{Var}[X_v] = \frac{\mathrm{d}(s,v)(1 - p)}{p^2}$
\end{itemize}
Niech $\{\ell_1,\dots, \ell_m\}$ będą liściami w $G$. Wtedy mamy 
\[
    Z = \max_{1\le i \le m} X_{\ell _i}
\] 
Połóżmy $d_i=\mathrm{d}(s,\ell_i)$ dla $1\le i \le m$ oraz bez starty ogólności niech $d_1\ge d_2\ge\dots\ge d_m$. Zauważmy, że $d_1$ to wysokość drzewa, $d_1=h$.
Wiemy, że funkcja $\max\{x_1,\dots, x_m\}$ jest wypukła więc z nierówności Jensena ~\ref{T:Jensen} otrzymujemy
\[
    \mathbb{E}[Z]=\mathbb{E}[\max_{1\le i \le m} X_{\ell _i}] \ge \max_{1\le i \le m} \mathbb{E}[X_{\ell _i}] = \max_{1\le i \le m} \frac{d_i}{p} = \frac{d_1}{p} = \frac{h}{p}
\]
Dla ograniczenie górnego korzystamy z ~\ref{F:max_inequality} oraz ~\ref{F:montonicity_of_expectation} i dostajemy
\[
    \mathbb{E}[Z]=\mathbb{E}[\max_{1\le i \le m} X_{\ell _i}] \le \sum_{i=1}^{m}\mathbb{E}[X_{\ell _i}] = \sum_{i=1}^{m} \frac{d_i}{p} = \frac{1}{p} \sum_{i=1}^{m} d_i \le \frac{1}{p} md_1=\frac{mh}{p}
\]
Ostatecznie 
\[
  \frac{h}{p} \le \mathbb{E}[Z] \le \frac{mh}{p} 
\]
Dla grafu $G=\mathrm{P}_n$ mamy $m=1, \; h=n-1$ a więc nierówności zamieniają sie w równość, z resztą zgodnie z poprzednimi wynikami. Oszacowania na $\mathbb{E}[Z]$ zdaje się więc nie móc poprawić w ogólności względem $m$ oraz $h$. \\
TODO : Generować losowe drzewa i zasymulować, może coś się wywnioskuje. Zgaduje, że mimo wszystko $\mathbb{E}[Z]$ powinno być $\mathcal{O}(n)$.
