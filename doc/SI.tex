\section{Dwa wierzchołki, jedna krawędź}

Na samym początku rozważmy najprostrzy graf, czyli o dwoch wierzchołkach $u,v$ połączonych krawędzią. Za wierzchołek startowy wybierzmy $u$. W tym przypadku istnieją tylko dwa możliwe stany systemu: $(I,S)$ oraz $(I,I)$. Przejście ze stanu $(I, S)$ do $(I, I)$ następuje z prawdopodobieństwem $p$ w każdej jednostce czasu. Zatem czas zarażenia drugiego wierzchołka $X_v$ ma rozkład geometryczny, $X_v \sim \mathrm{Geo}(p)$. Jeśli chodzi o rozkład $Y_t$ to mamy:
\begin{itemize}
    \item $\mathbb{P}[Y_t=1]=q^t$, bo próba zarażenia musiałaby nie udać się $t$ razy
    \item $\mathbb{P}[Y_t=2]=1-q^t$
\end{itemize}
Stąd $\mathbb{E}[Y_t]=1\cdot q^t + 2 \cdot (1-q^t) = 2-q^t$. Jeśli chodzi o zmienną $Z$ to zachodzi $Z=\max\{X_u,X_v\}=X_v$ a więc również $Z\sim \mathrm{Geo}(p)$.

\section{Analiza dla grafów $\mathrm{P}_n$}

Jako pierwszą rodzinę grafów rozważmy grafy ścieżkowe $\mathrm{P}_n$. Bez straty ogólności niech $V=\{1,2,\dots,n\}$. Załóżmy, że proces zaczyna się w wierzchołku $s=1$. Zatem infekcja rozchodzi się po grafie "od lewej do prawej". Dla tej rodziny grafów uda nam się wyznaczyć dokładny rozkład prawdopodobieństwa. \\
Dla ścieżki $\mathrm{P}_n$ z wierzchołkiem początkowym $s=1$,  
czasy zarażenia kolejnych wierzchołków tworzą ciąg zmiennych losowych
\[
X_1 = 0, \quad X_{k} = X_{k-1} + U_k, \quad k\in\{2,3,\dots,n\},
\]
gdzie $U_1,U_2,\dots,U_n \sim \mathrm{Geo}(p)$ oraz $U_1,U_2,\dots,U_n$ są niezależne. 

Widzimy zatem, że
\[
X_k \sim U_1 + U_2 + \dots + U_{k-1},
\]
a więc z \Cref{F:sum_of_geo_RV} $X_k$ ma rozkład ujemny dwumianowy o parametrach $(k-1, p)$, 
\[
X_k\sim \mathrm{NegBin}(k-1, p).
\]

Ponadto mamy:
\begin{itemize}
    \item $\mathbb{E}[X_k] = \frac{k-1}{p}$,
    \item $\mathrm{Var}[X_k] = \frac{(k-1)(1-p)}{p^2}$.
\end{itemize}

Aby obliczyć rozkład $Y_t$ zauważmy, że liczba dodatkowych zakażeń poza startowym wierzchołkiem do czasu $t$ to po prostu liczba sukcesów w $t$ niezależnych prób Bernoulliego. Musimy jednak pamiętać, że $Y_t$ nie może przekroczyć $n$. Zatem mamy dokładnie
\[
Y_t = \min\{n, 1 + B_t\}, \quad \text{gdzie} \quad B_t \sim \mathrm{Bin}(t,p).
\]
Pozwala to na wyznaczenie PMF dla $Y_t$:

Dla $1 \le k \le n-1$ mamy:
\[
\mathbb{P}[Y_t=k] = \mathbb{P}[B_t=k-1] = \binom{t}{k-1} p^{k-1} q^{t-k+1},
\]  

oraz dla $k = n$ mamy:
\[
\mathbb{P}[Y_t=n] = \mathbb{P}[B_t \ge n-1] = \sum_{j=n-1}^{t} \binom{t}{j} p^j q^{t-j}.
\]

Przejdźmy teraz do obliczania wartości oczekiwanej $Y_t$:
\begin{align*}
\mathbb{E}[Y_t] 
&= \sum_{k=1}^{n-1} k \cdot \mathbb{P}[Y_t=k] + n \cdot \mathbb{P}[Y_t=n] \\
&= \sum_{k=1}^{n-1} k \cdot \binom{t}{k-1} p^{k-1} q^{t-k+1} 
   + n \cdot \sum_{j=n-1}^{t} \binom{t}{j} p^j q^{t-j}.
\end{align*}

W pierwszej sumie podstawiamy $j = k-1$, co pozwala nam złączyć obie sumy i otrzymać:
\[
    \mathbb{E}[Y_t] = \sum_{j=0}^{t} \min\{n, 1+j\} \binom{t}{j} p^j q^{t-j}.
\]

Policzmy teraz asymptotykę dla $n \to \infty$. Wtedy $n > 1 + j$ dla wszystkich $0 \le j \le t$, a więc:
\[
    \lim_{n \to \infty}\mathbb{E}[Y_t] = \sum_{j=0}^{t} (1+j) \binom{t}{j} p^j q^{t-j}.
\]
Rozdzielając sumę na dwa składniki, otrzymujemy:
\[
    \lim_{n \to \infty}\mathbb{E}[Y_t] = \sum_{j=0}^{t} \binom{t}{j} p^j q^{t-j} 
+ \sum_{j=0}^{t} j \binom{t}{j} p^j q^{t-j}.
\]
Korzystając z \Cref{F:binomial} oraz \Cref{F:binomial1} otrzymujemy
\[
    (p+q)^t+tp(p+q)^{t-1}=1+tp
\]
Zatem
\[
    \lim_{n \to \infty}\mathbb{E}[Y_t] = 1+tp.
\]

Czas całkowitego zainfekowania grafu $\mathrm{P}_n$ to $Z = \max\{X_1,X_2,\dots,X_n\} = X_n$. Zatem rozkład zmiennej $Z$ jest już nam znany a wartość oczekiwana wynosi 
\[
    \mathbb{E}[Z]=\frac{n-1}{p}.
\]


\section{Analiza dla grafów $\mathrm{S}_n$}

Następnie rozpatrzmy rodzinę grafów gwiazd $\mathrm{S}_n$. Przyjmujemy $V=\{0,1,2,\dots,n\}$ oraz, że wierzchołek $0$ jest środkiem gwiazdy. W modelu dla tej rodziny zakładamy również $s=0$. Propagacja rozchodzi się tutaj po każdym ramieniu gwiazdy niezależnie. 
Stąd mamy $X_v \sim \mathrm{Geo}(p)$ dla każdego $v\in\{1,2,\dots,n\}$. Zauważmy ponadto, że zmienne $X_1,X_2,\dots,X_n$ są od siebie niezależne.\\

Kwestia $Y_t$ jest również dość prosta. Skoro każdy propagacja działa na każdym wierzchołku niezależnie to zmienna $Y_t$ jest wynikiem $n$ prób Bernoulliego. Sukces pojedynczej próby to prawdopodobieństwo, że zmienna $X_v$ o rozkładzie geometrycznym po conajwyżej $t$ jednostkach czasu osiągnie swój sukces. A więc jest to $\mathbb{P}[X_v\le t]=1-q^t$. Podsumowując mamy
\[
    Y_t \sim \mathrm{Bin}(n, 1-q^t)
\]
Stąd oczywiście otrzymujemy 
\[
    \mathbb{E}[Y_t] = n\cdot (1-q^t). 
\]

Przejdźmy teraz to zmiennej $Z$. Przypomnijmy, że $Z=\max\{X_1,X_2,\dots,X_n\}$. Skoro zmienne te są IID, to z \Cref{F:max_CDF} mamy 
\[
    \mathbb{P}[Z\le t] = (1-q^t)^n
\]
Policzmy teraz wartość oczekiwaną $Z$ na mocy \Cref{F:expected_value_tail_sum}:
\begin{align*}
\mathbb{E}[Z] 
&= \sum_{k=1}^{\infty} \mathbb{P}[Z\ge k] 
 = \sum_{k=1}^{\infty} 1 - \mathbb{P}[Z\le k-1]
 = \sum_{k=1}^{\infty}  1 - (1-q^{k-1})^n  \\
&= \sum_{k=0}^{\infty}  1 - (1-q^k)^n 
 = \sum_{k=0}^{\infty} \left( 1 - \sum_{j=0}^{n} \binom{n}{j} (-1)^j q^{kj} \right) 
 = \sum_{k=0}^{\infty} \sum_{j=1}^{n} \binom{n}{j} (-1)^{j+1} q^{kj} \\
&= \sum_{j=1}^{n} \sum_{k=0}^{\infty} \binom{n}{j} (-1)^{j+1} (q^j)^k 
 = \sum_{j=1}^{n} \binom{n}{j} \frac{(-1)^{j+1}}{1-q^j}.
\end{align*}
Nie jest to jednak przyzwoity wynik i nie ma postaci zwartej. Spróbujmy zatem wyznaczyć asymptotykę $\mathbb{E}[Z]$. Skoro $\mathbb{E}[Z] = \sum_{k=0}^{\infty}  1 - (1-q^k)^n$ to z \Cref{F:approximation_of_sum_by_an_integral} możemy oszacować tę sumę. Połóżmy $f(x) = 1 - (1 - e^{-\alpha x})^n$ gdzie $\alpha = -\log(q)$. Oczywiście $f(0)=1$ , $f(\infty)=0$ oraz $f$ jest malejąca a więc
\[
    \int_{0}^{\infty} f(x) \; \mathrm{d}x \le \mathbb{E}[Z] \le  1 + \int_{0}^{\infty} f(x) \; \mathrm{d}x
\]
W celu obliczenia tej całki podstawmy $u = 1 - e^{-\alpha x}$. 
Wtedy $\mathrm{d}u = \alpha e^{-\alpha x} \, \mathrm{d}x$, 
a więc $\mathrm{d}x = \frac{1}{\alpha(1-u)} \, \mathrm{d}u$. 
Ponadto $u(0) = 0$, $u(\infty) = 1$ (bo $\alpha > 0$). 
Zatem całka ma postać:
\[
\int_{0}^{\infty} 1 - (1 - e^{-\alpha x})^n \, \mathrm{d}x
= \frac{1}{\alpha} \int_{0}^{1} \frac{1 - u^n}{1 - u} \, \mathrm{d}u
= \frac{1}{\alpha} \int_{0}^{1} \sum_{j=0}^{n-1} u^j \, \mathrm{d}u
= \frac{1}{\alpha} \sum_{j=0}^{n-1} \frac{1}{j+1}
= \frac{H_n}{\alpha}.
\]

Zauważmy, że $-\log(q)=\log(\frac{1}{1-p})$ a więc ostatecznie dostajemy:
\[
    \frac{H_n}{\log(\frac{1}{1-p})} \le \mathbb{E}[Z] \le \frac{H_n}{\log(\frac{1}{1-p})} + 1
\]
Mamy więc asymptotyczny przewidywany czas zarażenia grafu $\mathrm{S}_n$.
\[
    \mathbb{E}[Z] \sim \frac{H_n}{\log(\frac{1}{1-p})}
\]

\section{Monotoniczność czasu zarażenia}
Po rozważeniu tych dwóch rodzin grafów widzimy znaczną różnicę w wartościach oczekiwnaych zmiennych $Y_t$ oraz $Z$. Dla grafów ścięzkowych minimalna liczb rund potrzebnych do zainfekowania całego grafu wynosi $t=n-1$ natomiast dla gwiazd jest to zaledwie $t=1$. Widzimy, że w pewnym sensie najlepszy przypadek sprzyjający szybkiej propagacji jest taki, w którym źródło $s$ jest połączone z wszyskimi pozostałymi wierzchołkami grafu. Z drugiej strony najgorsza sytuacja ma miejsce jeśli istnieje daleko oddalony węzeł, szczególnie z mało liczbą ścieżek do niego prowadzących, tak jak dla grafów ścieżkowych. Teraz postaramy się uogólnić tą obserwację. 

\begin{theorem}\label{T:montonicity_of_total_infection}
Niech $G=(V,E)$ będzie grafem spójnym a $G'=(V,E')$ spójnym podgrafem $G$. Załózmy, że $\mathbf{X}$ jest procesem stochastycznym w modelu SI na $G$ oraz $G'$ jednocześnie z tym samym źródłem $s\in V$. Jeśli przez $Z$ oznaczymy czas całkowitego zarażenia $G$ i odpowiednio przez $Z'$ dla $G'$ to wtedy zachodzi nierówność $\mathbb{E}[Z]\le\mathbb{E}[Z']$. 
\end{theorem}

Intuicyjnie sprawa jest oczywista. Mając mniej krawędzi w grafie potrzebujemy więcej czasu na rozprzestrzenienie w nim informacji.

\begin{proof}
Oznaczmy przez $\mathcal{I}_t$ zainfekowane wierzchołki w $G$ a przez $\mathcal{I}_t'$ w $G'$. Wtedy $\mathcal{I}'_t\subseteq\mathcal{I}_t$ dla dowolnego $t\in\mathbb{N}$. Ponadto mamy
\begin{itemize}
    \item $Z = \min\{t\in\mathbb{N} : \mathcal{I}_t=V\}$
    \item $Z' = \min\{t\in\mathbb{N} : \mathcal{I}_t'=V\}$
\end{itemize}     
Niech $Z' = \tau$. Wtedy $\mathcal{I}'_\tau =V$ a więc $V\subseteq \mathcal{I}_t$. Zatem $\mathcal{I}_\tau = V$ i $Z\le \tau$. Korzystając z \Cref{F:montonicity_of_expectation} dostajemy $\mathbb{E}[Z]\le\mathbb{E}[Z']$.
\end{proof}

W praktyce oznacza to, że jeżeli znamy średni czas zainfekowania dowolnego podgrafu $G$ to znamy ogarniczenie górne na czas dla całego grafu.


\section{Ograniczenia górne na $\mathbb{E}[Z]$}
Postarajmy się teraz oszacować z góry sensownie wartość $\mathbb{E}[Z]$ dla dowolneg grafu.

\begin{theorem}\label{T:upper_bound_on_EZ}
Niech $G=(V,E)$ będzie grafem o $n$ wierzchołkach zaś $s\in V$ będzie ustalonym źródłem. Ozanczmy przez $\ell = \epsilon(s)$. Wtedy zachodzi
\[
    \mathbb{E}[Z] \le \ell  + \ell \cdot \frac{\log(\frac{n-1}{\ell}) + 1}{\log(\frac{1}{1-p})}
\]
\end{theorem}

\begin{proof}
Dla $0\le j \le \ell$ kładziemy $A_j = \{v \in V : \mathrm{d}(s,v) = j\}$ oraz $n_j= |A_j|$. Oczywiście $n_0=1$ a więc $n_1+\dots+ n_\ell = n -1 $. Dalej zdefiniujmy zmienne losowe $T_j = \min\{t\in\mathbb{N} : A_j \subseteq \mathcal{I}_t\}$. Zmienna $T_j$ określa czas potrzebny do zainfekowania wierzchołków oddalonych o $j$ od źródła. Udowodnijmy najpierw przydatny lemmat.

\begin{lemma}\label{L:helper_lemma}
Niech $U_j = T_j - T_{j-1}$ dla $1 \le j \le \ell$. Wtedy $\mathbb{E}[U_j] \le \frac{H_{n_j}}{\log(\frac{1}{1-p})} + 1$.
\end{lemma}
\begin{proof}
$U_j$ to czas potrzebny na zarażenie wierzchołków $A_j$ podczas gdy $A_{j-1}$ są juz zarażone. Wybierzmy podgraf $G'$ w taki sposób, żeby każdy wierzchołek z $\in A_j$ był połączony dokładnie jedną krawędzią z którym kolwiek z wierzchołków ze zbioru $A_{j-1}$. Wtedy rozkład propagacji na $G'$ jest izomorficzny z tym dla $\mathrm{S}_{n_j}$ bo $n_j=|A_j|$. Z analizy propagacji dla grafow gwiazd otrzymujemy $\mathrm{S}_{n_j} \le \frac{H_{n_j}}{\log(\frac{1}{1-p})} + 1$. Natomiast z \Cref{T:montonicity_of_total_infection} dostajemy porządany wynik.
\end{proof}

Teraz możemy udowodnić ogarniczenie na $\mathbb{E}[Z]$. Z monotoniczności propagacji mamy $\mathbb{E}[Z] \le \mathbb{E}[T_\ell]$ oraz $T_\ell = \sum_{j=1}^{\ell} U_j$. Mamy zatem

\begin{equation*}
\begin{aligned}
\mathbb{E}[Z] 
&\le \mathbb{E}[T_\ell] 
  = \mathbb{E}\left[\sum_{j=1}^{\ell} U_j\right] 
  = \sum_{j=1}^{\ell} \mathbb{E}[U_j] 
  \le \sum_{j=1}^{\ell} \frac{H_{n_j}}{\log(\frac{1}{1-p})} + 1 \\
&= \ell + \frac{1}{\log(\frac{1}{1-p})} \sum_{j=1}^{\ell} H_{n_j} 
  \le \ell + \frac{1}{\log(\frac{1}{1-p})} \sum_{j=1}^{\ell} 1 + \log(n_j) \\
&= \ell + \frac{\ell}{\log(\frac{1}{1-p})} \cdot \left(1 + \sum_{j=1}^{\ell} \log(n_j) \right) \\
&= \ell + \frac{\ell}{\log(\frac{1}{1-p})} \cdot \left(1 + \log \left(\prod_{j=1}^{\ell} n_j\right)\right) \\
&\le \ell + \frac{\ell}{\log(\frac{1}{1-p})} \cdot \left(1 + \log \left(\frac{1}{\ell} \sum_{j=1}^{\ell} n_j\right) \right) \\
&= \ell + \frac{\ell}{\log(\frac{1}{1-p})} \cdot \left(1 + \log \left(\frac{n-1}{\ell}\right) \right) = \ell  + \ell \cdot \frac{\log(\frac{n-1}{\ell}) + 1}{\log(\frac{1}{1-p})}.
\end{aligned}
\end{equation*}
gdzie w linijce pierwszej wykorzystując z monotoniczności propagacji, w drugiej z \Cref{F:harmonic_upper_bound} a w piątej z nierówności między średnimi (\ref{F:AM_GM}).
\end{proof}

Porównajmy przed chwilą udowdnione twierdzenie z poprzednimi wynikami. Dla rodziny $\mathrm{P}_n$ mamy $\ell = n - 1$. Dodatkowo korzystając z \Cref{F:log_vs_x} mamy
\[
    \mathbb{E}[Z] \le n-1 + (n-1) \cdot \frac{1}{p}
\]
Przypomnijmy, że faktyczna wartość oczekiwana jest równa $\frac{n-1}{p}$ więc oszacowanie jest dość ostre. 
Z kolei dla rodziny $\mathrm{S}_n$ mamy $\ell=1$ oraz $n+1$ wierzchołków a więc
\[
    \mathbb{E}[Z] \le 1 + \frac{\log(n) + 1}{\log(\frac{1}{1-p})}
\]
Ponownie oszacowanie jest dość dokładne.


\section{Analiza dla drzew}

Rozważmy drzewo $G = (V, E)$ oraz ustalony wierzchołek początkowy $s \in V$, 
który traktujemy jako korzeń drzewa. Dla $v\in V$ oznaczmy  $d_v=\mathrm{d}(s,v)$. Skoro $G$ jest drzewem to istnieje dokładnie jedna ścieżka od $s$ do $v$, powiedzmy $s,v_1,...,v_{d-1}, v$. Ponieważ infekcja rozprzestrzenia się od korzenia $s$ wzdłuż krawędzi drzewa, 
każde zakażenie wymaga sukcesu w niezależnym doświadczeniu Bernoulliego o prawdopodobieństwie $p$.
W konsekwencji, aby infekcja dotarła z $s$ do $v$, 
musi wystąpić $\mathrm{d}_v$ kolejnych sukcesów. Zatem rozkład $X_v$ pokrywa się z rozkładem tej zmiennej dla grafu $\mathrm{P}_{d+1}$ na wierzchołkach $\{s,v_1,...,v_{d-1}, v\}$. 
Zatem 
\[
    X_v\sim \mathrm{NegBin}(\mathrm{d}_v,p)
\]
oraz
\begin{itemize}
    \item $\mathbb{E}[X_v] = \frac{\mathrm{d}_v}{p}$
    \item $\mathrm{Var}[X_v] = \frac{\mathrm{d}_v\cdot(1 - p)}{p^2}$
\end{itemize}


\begin{lemma}\label{L:Formula_EYt}
Dla dowolnego $t\in\mathbb{N}$ wartość oczekiwana zmiennej $Y_t$ wyraża się wzorem
\[
    \mathbb{E}[Y_t] = \sum_{v\in V} \mathbb{P}[X_v \le t]
\]    
\end{lemma}

\begin{proof}
Mamy $Y_t=|\{v\in V: X_v \le t\}|$ zatem $Y_T=\sum_{v\in V}  \mathbf{1}_{\{X_v\le t\}}$. Nakładając na tą równość operator $\mathbb{E}$ otrzymujemy:
\[
    \mathbb{E}[Y_t] = \mathbb{E}\left[ \sum_{v\in V}  \mathbf{1}_{\{X_v\le t\}}\right]= \sum_{v\in V} \mathbb{E}[\mathbf{1}_{\{X_v\le t\}}] = \sum_{v\in V} \mathbb{P}[X_v \le t]
\]    
\end{proof}

Przejdźmy teraz to obliczania średniej liczby zainfekowanych wierzchołków w czasie $t$. Oznaczmy przez $F(t;m,p)$ CDF zmiennej o rozkładzie $\mathrm{NegBin}(m,p)$. Z \Cref{L:Formula_EYt} otrzymujemy
\[
    \mathbb{E}[Y_t] = \sum_{v\in V} F(t; d_v, p)
\]
Połóźmy $n_j = |\{v\in V: d_v=j\}|$ dla $0\le j \le h$. Wtedy 
\[
    \mathbb{E}[Y_t] = \sum_{j=0}^{h} n_j\cdot F(t; j, p)
\]
Ponadto gdy $t<j\le h$ to $F(t; j, p)$ bo żaden wierzchołek w odległości od korzenia większej niż liczba rund od korzenia nie może zostać zarażony. Możemy więc zmniejszyć granice sumowania 
\[
    \mathbb{E}[Y_t] = \sum_{j=0}^{\min\{h,t\}} n_j\cdot F(t; j, p)
\]

Oszacujmy teraz średni czas całkowity czas propagacji drzewa.
Niech $\{u_1,\dots, u_m\}$ będą liściami w $G$. Wtedy mamy $Z = \max_{1\le i \le m} X_{u _i}$.
Zauważmy, że $\epsilon(s) = \max_{1\le i \le m} \mathrm{d}_{u_i}$ i jest to wysokość drzewa. Oznaczmy ją przez $h$. Z nierówności Jensena (\cref{F:Jensen}) dla funkcji $\max\{x_1,\dots,x_m\}$ otrzymujemy
\[
    \mathbb{E}[Z]=\mathbb{E}[\max_{1\le i \le m} X_{u _i}] \ge \max_{1\le i \le m} \mathbb{E}[X_{u _i}] = \max_{1\le i \le m} \frac{\mathrm{d}_{u_i}}{p} = \frac{h}{p}
\]
Największą wysokość ma drzewo, które jest ścieżka i wtedy $h=n-1$. Zgodnie z poprzednimi wyliczeniami jest to dobre oszacowanie. Aby ogarniczyć $\mathbb{E}[Z]$ z góry skorzystamy z \Cref{T:upper_bound_on_EZ}:
\[
    \mathbb{E}[Z] \le h  + h \cdot \frac{\log(\frac{n-1}{h}) + 1}{\log(\frac{1}{1-p})}
\]
